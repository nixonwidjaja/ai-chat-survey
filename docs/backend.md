# Backend Report

## Section Introduction
This section serves as a comprehensive exploration of the backend infrastructure underpinning our AI chatbot survey system. Here, we present an in-depth analysis of the LLM (Large Language Model) at the heart of our solution, along with a detailed examination of the backend architecture. Through this report, we aim to provide a thorough understanding of our model selection rationale, its integration into the survey framework, and the overarching architecture supporting its functionality. Furthermore, we discuss our approach to model evaluation, post-deployment tracking, and strategies for continuous improvement.

## Literature Review
- Insert literature review regarding traditional surveys as well as efforts to 
integrate LLMs into surveys

## Backend Architecture
- Insert description and diagrams of backend architecture
- Rubrics:
  - Justification for models/solution chosen, probably by tying back to user interviews
    from Front-End team
  
## Model Evaluation
- [Model Evaluation](evaluation.md)
- Rubrics: 
  - In-depth study of performance of model and it's failings.
  - Interpretation of model

## Post-Deployment Tracking and Improvement
- Insert model evaluation
- Rubrics:
   - Demonstrate an awareness of how model can be tracked and improved after
     deployment.

## Conclusion
In conclusion, this backend report has provided a detailed examination of the infrastructure supporting our AI chatbot survey system. We have explored the core components, including the LLM model, and discussed the rationale behind our model selection and its integration into the survey framework. Additionally, we have examined the backend architecture, shedding light on the design decisions and the system's functionality. Through thorough model evaluation and post-deployment tracking, we have gained insights into the performance of our solution and identified avenues for improvement. 
